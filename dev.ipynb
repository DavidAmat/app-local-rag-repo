{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Represents a file or directory node.\n",
    "    - name: The name of the file or folder.\n",
    "    - type: Either \"file\" or \"folder\".\n",
    "    - parent: Reference to the parent Node (None for root).\n",
    "    - children: List of child Nodes (only applicable if type == \"folder\").\n",
    "    \"\"\"\n",
    "    def __init__(self, name, node_type, parent=None):\n",
    "        self.name = name\n",
    "        self.type = node_type  # \"folder\" or \"file\"\n",
    "        self.parent = parent\n",
    "        self.children = []  # Only meaningful for folders\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        self.children.append(child_node)\n",
    "\n",
    "    def tree_repr(self, prefix=\"\"):\n",
    "        \"\"\"\n",
    "        Recursively generate a string representation similar to the \"tree .\" command.\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        connector = \"└── \" if prefix.endswith(\"└── \") else \"├── \"\n",
    "        lines.append(f\"{prefix}{self.name}\")\n",
    "        if self.type == \"folder\":\n",
    "            # Prepare new prefix for children\n",
    "            child_prefix = prefix + (\"    \" if prefix.endswith(\"└── \") else \"│   \")\n",
    "            count = len(self.children)\n",
    "            for idx, child in enumerate(self.children):\n",
    "                # For the last child, adjust the prefix\n",
    "                next_prefix = prefix + (\"    \" if idx == count - 1 else \"│   \")\n",
    "                lines.append(child.tree_repr(prefix=next_prefix))\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Node(name='{self.name}', type='{self.type}')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileTreeGraph:\n",
    "    \"\"\"\n",
    "    Builds a file tree from a given directory using two representations:\n",
    "    1. A dictionary-based representation: { \"name\": <str>, \"files\": [<str>], \"folders\": [<dict>] }\n",
    "    2. An object-based representation using the Node class.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_path):\n",
    "        self.root_path = os.path.abspath(root_path)\n",
    "        self.dict_tree = None\n",
    "        self.node_tree = None\n",
    "\n",
    "    def build_dict_tree(self, current_path=None):\n",
    "        \"\"\"\n",
    "        Recursively builds the dictionary representation of the file tree.\n",
    "        \"\"\"\n",
    "        if current_path is None:\n",
    "            current_path = self.root_path\n",
    "\n",
    "        tree = {\"name\": os.path.basename(current_path) or current_path,\n",
    "                \"files\": [],\n",
    "                \"folders\": []}\n",
    "        try:\n",
    "            for entry in sorted(os.listdir(current_path)):\n",
    "                full_path = os.path.join(current_path, entry)\n",
    "                if os.path.isdir(full_path):\n",
    "                    tree[\"folders\"].append(self.build_dict_tree(full_path))\n",
    "                else:\n",
    "                    tree[\"files\"].append(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading directory {current_path}: {e}\")\n",
    "        return tree\n",
    "\n",
    "    def build_node_tree(self, current_path=None, parent_node=None):\n",
    "        \"\"\"\n",
    "        Recursively builds the Node-based representation of the file tree.\n",
    "        \"\"\"\n",
    "        if current_path is None:\n",
    "            current_path = self.root_path\n",
    "\n",
    "        node = Node(name=os.path.basename(current_path) or current_path, node_type=\"folder\", parent=parent_node)\n",
    "        try:\n",
    "            for entry in sorted(os.listdir(current_path)):\n",
    "                full_path = os.path.join(current_path, entry)\n",
    "                if os.path.isdir(full_path):\n",
    "                    child_node = self.build_node_tree(full_path, parent_node=node)\n",
    "                    node.add_child(child_node)\n",
    "                else:\n",
    "                    file_node = Node(name=entry, node_type=\"file\", parent=node)\n",
    "                    node.add_child(file_node)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading directory {current_path}: {e}\")\n",
    "        return node\n",
    "\n",
    "    def build_graphs(self):\n",
    "        \"\"\"\n",
    "        Build both the dictionary and node representations.\n",
    "        \"\"\"\n",
    "        self.dict_tree = self.build_dict_tree()\n",
    "        self.node_tree = self.build_node_tree()\n",
    "\n",
    "    def dict_tree_repr(self, tree=None, indent=\"\"):\n",
    "        \"\"\"\n",
    "        Generate a string representation for the dictionary tree,\n",
    "        similar to the output of the \"tree .\" command.\n",
    "        \"\"\"\n",
    "        if tree is None:\n",
    "            tree = self.dict_tree\n",
    "        lines = []\n",
    "        lines.append(f\"{indent}{tree['name']}\")\n",
    "        # Files in the current folder\n",
    "        for file in tree[\"files\"]:\n",
    "            lines.append(f\"{indent}    {file}\")\n",
    "        # Recursively process folders\n",
    "        for folder in tree[\"folders\"]:\n",
    "            lines.append(self.dict_tree_repr(folder, indent + \"    \"))\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def get_graphs(self):\n",
    "        \"\"\"\n",
    "        Returns both representations.\n",
    "        \"\"\"\n",
    "        if self.dict_tree is None or self.node_tree is None:\n",
    "            self.build_graphs()\n",
    "        return {\"dict_tree\": self.dict_tree, \"node_tree_repr\": self.node_tree.tree_repr()}\n",
    "    \n",
    "    def export_to_yaml(self, output_file):\n",
    "        \"\"\"\n",
    "        Exports the dictionary tree representation to a YAML file.\n",
    "        \"\"\"\n",
    "        # Ensure the dict tree is built\n",
    "        if self.dict_tree is None:\n",
    "            self.dict_tree = self.build_dict_tree()\n",
    "        try:\n",
    "            with open(output_file, 'w') as f:\n",
    "                yaml.dump(self.dict_tree, f, default_flow_style=False)\n",
    "            print(f\"YAML exported to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to export YAML: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/david/Documents/glovo/machine-learning-platform/widget_framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftg = FileTreeGraph(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML exported to tree.yaml\n"
     ]
    }
   ],
   "source": [
    "ftg.export_to_yaml(\"tree.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Dependecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Set\n",
    "\n",
    "class PythonImportDAG:\n",
    "    \"\"\"\n",
    "    Builds a nested DAG graph of Python file imports starting from a given entry Python file.\n",
    "    The DAG includes dependencies between files traced via imports.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_path: str, entry_file: str):\n",
    "        \"\"\"\n",
    "        Initialize the PythonImportDAG.\n",
    "        \n",
    "        :param root_path: The root directory of the project (like \"machine-learning-platform\").\n",
    "        :param entry_file: The relative path of the entry Python file (relative to root_path).\n",
    "        \"\"\"\n",
    "        self.root_path = Path(root_path).resolve()  # Absolute path of the project root\n",
    "        self.entry_file = (self.root_path / entry_file).resolve()  # Absolute path of the entry file\n",
    "        self.file_tree_graph = FileTreeGraph(root_path)  # Use FileTreeGraph for file path checks\n",
    "        self.file_tree_graph.build_graphs()  # Build the file tree\n",
    "        self.import_dag = {}  # The nested DAG graph\n",
    "\n",
    "    def build_import_dag(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Main function to build the import DAG starting from the entry file.\n",
    "        :return: The nested DAG graph as a dictionary.\n",
    "        \"\"\"\n",
    "        self.import_dag = self._trace_file_imports(self.entry_file)\n",
    "        return self.import_dag\n",
    "\n",
    "    def _trace_file_imports(self, file_path: Path, recursion_stack=None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Recursively trace the imports of a Python file and build a DAG.\n",
    "        This version:\n",
    "        - Uses a recursion stack (list) to detect circular imports;\n",
    "        - Allows a file to appear multiple times if imported along different branches.\n",
    "        \"\"\"\n",
    "        if recursion_stack is None:\n",
    "            recursion_stack = []\n",
    "\n",
    "        # Detect circular import by checking if the file is already in the recursion path\n",
    "        if file_path in recursion_stack:\n",
    "            return {}  # Return an empty dict to avoid infinite loops\n",
    "\n",
    "        # Push current file onto the recursion stack\n",
    "        recursion_stack.append(file_path)\n",
    "\n",
    "        # Initialize the DAG for the current file\n",
    "        dag = {\n",
    "            \"name\": str(file_path.relative_to(self.root_path)),\n",
    "            \"imports\": [],\n",
    "            \"imported_objects\": []  # Add imported objects for the current file\n",
    "        }\n",
    "\n",
    "\n",
    "        # Parse imports in this file\n",
    "        imports = self._get_imports_from_file(file_path)\n",
    "\n",
    "        # Recursively process each import\n",
    "        for import_path in imports:\n",
    "            # If the import is a dictionary, extract module and objects\n",
    "            if isinstance(import_path, dict):\n",
    "                module = import_path[\"module\"]\n",
    "                objects = import_path[\"objects\"]\n",
    "                resolved_path = self._resolve_import_to_path(module)\n",
    "            else:\n",
    "                resolved_path = self._resolve_import_to_path(import_path)\n",
    "                objects = []  # No specific objects if it's a simple module import\n",
    "\n",
    "            if resolved_path:\n",
    "                dag_entry = self._trace_file_imports(resolved_path, recursion_stack) if resolved_path else {}\n",
    "                dag_entry[\"imported_objects\"] = objects\n",
    "                if dag_entry and all(child.get(\"name\") != dag_entry.get(\"name\") for child in dag[\"imports\"]):\n",
    "                    dag[\"imports\"].append(dag_entry)\n",
    "\n",
    "        # Pop from the stack after processing\n",
    "        recursion_stack.pop()\n",
    "        return dag\n",
    "\n",
    "\n",
    "    def _get_imports_from_file(self, file_path: Path) -> List[str]:\n",
    "        \"\"\"\n",
    "        Parse a Python file and extract all import statements.\n",
    "        \n",
    "        :param file_path: The absolute path of the Python file to parse.\n",
    "        :return: A list of imported module/package names.\n",
    "        \"\"\"\n",
    "        imports = []\n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                tree = ast.parse(file.read(), filename=str(file_path))\n",
    "\n",
    "            # Extract import statements\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.Import):\n",
    "                    for alias in node.names:\n",
    "                        imports.append(alias.name)\n",
    "                elif isinstance(node, ast.ImportFrom):\n",
    "                    if node.module:\n",
    "                        imported_objects = [alias.name for alias in node.names]\n",
    "                        imports.append({\"module\": node.module, \"objects\": imported_objects})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse {file_path}: {e}\")\n",
    "\n",
    "        return imports\n",
    "\n",
    "    def _resolve_import_to_path(self, import_path: str) -> Path:\n",
    "        \"\"\"\n",
    "        Resolve an import path to a file in the project directory.\n",
    "        \n",
    "        :param import_path: The import path as a string (e.g., \"product_recommender.api\").\n",
    "        :return: The absolute path of the imported file if found, None otherwise.\n",
    "        \"\"\"\n",
    "        # Convert the import path to a file path (e.g., \"product_recommender.api\" -> \"product_recommender/api.py\")\n",
    "        potential_path = self.root_path / import_path.replace(\".\", \"/\") / \"__init__.py\"  # Handle packages\n",
    "        if potential_path.exists():\n",
    "            return potential_path\n",
    "\n",
    "        potential_path = self.root_path / f\"{import_path.replace('.', '/')}.py\"  # Handle modules\n",
    "        if potential_path.exists():\n",
    "            return potential_path\n",
    "\n",
    "        # If not found, return None (likely a third-party library or built-in module)\n",
    "        return None\n",
    "\n",
    "    def visualize_import_dag(self, dag=None, indent=0) -> None:\n",
    "        \"\"\"\n",
    "        Pretty print the import DAG, including imported objects.\n",
    "\n",
    "        :param dag: The DAG to print (defaults to the main import_dag).\n",
    "        :param indent: The current indentation level for pretty printing.\n",
    "        \"\"\"\n",
    "        if dag is None:\n",
    "            dag = self.import_dag\n",
    "\n",
    "        # Print the current file name\n",
    "        print(\"  \" * indent + f\"- {dag.get('name', '<unknown>')}\")\n",
    "\n",
    "        # Print the imported objects for this file, if any\n",
    "        for obj in dag.get(\"imported_objects\", []):\n",
    "            print(\"  \" * (indent + 1) + f\"  * {obj}\")\n",
    "\n",
    "        # Recursively print child imports\n",
    "        for child in dag.get(\"imports\", []):\n",
    "            if child:  # Skip empty dictionaries\n",
    "                self.visualize_import_dag(child, indent + 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: root folder \"machine-learning-platform\", entry file \"product_recommender/api.py\"\n",
    "root = \"/home/david/Documents/glovo/machine-learning-platform\"\n",
    "entry = \"widget_framework/src/widget_builder.py\"\n",
    "\n",
    "# Build the import DAG\n",
    "import_dag_builder = PythonImportDAG(root, entry)\n",
    "dag = import_dag_builder.build_import_dag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'widget_framework/src/widget_builder.py',\n",
       " 'imports': [{'name': 'widget_framework/constants.py',\n",
       "   'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "     'imports': [],\n",
       "     'imported_objects': ['user_ids_staff']}],\n",
       "   'imported_objects': ['USERS_STAFF']},\n",
       "  {'name': 'widget_framework/src/experiment_string.py',\n",
       "   'imports': [{'name': 'widget_framework/src/utils.py',\n",
       "     'imports': [{'name': 'widget_framework/constants.py',\n",
       "       'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "         'imports': [],\n",
       "         'imported_objects': ['user_ids_staff']}],\n",
       "       'imported_objects': ['FS_MAX_RETRIES', 'SLEEP_MS', 'TIMEOUT_IN_MS']}],\n",
       "     'imported_objects': ['Utils']}],\n",
       "   'imported_objects': ['ExperimentString']},\n",
       "  {'name': 'widget_framework/src/user_segmentation/user_segment.py',\n",
       "   'imports': [{'name': 'widget_framework/src/utils.py',\n",
       "     'imports': [{'name': 'widget_framework/constants.py',\n",
       "       'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "         'imports': [],\n",
       "         'imported_objects': ['user_ids_staff']}],\n",
       "       'imported_objects': ['FS_MAX_RETRIES', 'SLEEP_MS', 'TIMEOUT_IN_MS']}],\n",
       "     'imported_objects': ['Utils']}],\n",
       "   'imported_objects': ['UserSegmentation']},\n",
       "  {'name': 'widget_framework/src/utils.py',\n",
       "   'imports': [{'name': 'widget_framework/constants.py',\n",
       "     'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "       'imports': [],\n",
       "       'imported_objects': ['user_ids_staff']}],\n",
       "     'imported_objects': ['FS_MAX_RETRIES', 'SLEEP_MS', 'TIMEOUT_IN_MS']}],\n",
       "   'imported_objects': ['ContractInput', 'Utils']},\n",
       "  {'name': 'widget_framework/src/widget_content/widget_content.py',\n",
       "   'imports': [{'name': 'widget_framework/constants.py',\n",
       "     'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "       'imports': [],\n",
       "       'imported_objects': ['user_ids_staff']}],\n",
       "     'imported_objects': ['BYO_WIDGET_ID', 'MAP_FILTER_NAMES']},\n",
       "    {'name': 'widget_framework/src/utils.py',\n",
       "     'imports': [{'name': 'widget_framework/constants.py',\n",
       "       'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "         'imports': [],\n",
       "         'imported_objects': ['user_ids_staff']}],\n",
       "       'imported_objects': ['FS_MAX_RETRIES', 'SLEEP_MS', 'TIMEOUT_IN_MS']}],\n",
       "     'imported_objects': ['ContractInput', 'Utils']}],\n",
       "   'imported_objects': ['WidgetContent']},\n",
       "  {'name': 'widget_framework/src/widget_ranking/widget_ranker.py',\n",
       "   'imports': [{'name': 'widget_framework/constants.py',\n",
       "     'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "       'imports': [],\n",
       "       'imported_objects': ['user_ids_staff']}],\n",
       "     'imported_objects': ['BUFFER_NUM_WIDGETS']},\n",
       "    {'name': 'widget_framework/src/experiment_string.py',\n",
       "     'imports': [{'name': 'widget_framework/src/utils.py',\n",
       "       'imports': [{'name': 'widget_framework/constants.py',\n",
       "         'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "           'imports': [],\n",
       "           'imported_objects': ['user_ids_staff']}],\n",
       "         'imported_objects': ['FS_MAX_RETRIES', 'SLEEP_MS', 'TIMEOUT_IN_MS']}],\n",
       "       'imported_objects': ['Utils']}],\n",
       "     'imported_objects': ['ExperimentString']},\n",
       "    {'name': 'widget_framework/src/utils.py',\n",
       "     'imports': [{'name': 'widget_framework/constants.py',\n",
       "       'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "         'imports': [],\n",
       "         'imported_objects': ['user_ids_staff']}],\n",
       "       'imported_objects': ['FS_MAX_RETRIES', 'SLEEP_MS', 'TIMEOUT_IN_MS']}],\n",
       "     'imported_objects': ['UNDEF_STR',\n",
       "      'ClassGroups',\n",
       "      'ContractInput',\n",
       "      'FactoryGroups',\n",
       "      'ParsedContractInput',\n",
       "      'Utils']},\n",
       "    {'name': 'widget_framework/src/widget_competing/widget_competing.py',\n",
       "     'imports': [{'name': 'widget_framework/src/utils.py',\n",
       "       'imports': [{'name': 'widget_framework/constants.py',\n",
       "         'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "           'imports': [],\n",
       "           'imported_objects': ['user_ids_staff']}],\n",
       "         'imported_objects': ['FS_MAX_RETRIES', 'SLEEP_MS', 'TIMEOUT_IN_MS']}],\n",
       "       'imported_objects': ['ClassGroups', 'ContractInput', 'Utils']},\n",
       "      {'name': 'widget_framework/src/widget_competing/policies.py',\n",
       "       'imports': [{'name': 'widget_framework/src/utils.py',\n",
       "         'imports': [{'name': 'widget_framework/constants.py',\n",
       "           'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "             'imports': [],\n",
       "             'imported_objects': ['user_ids_staff']}],\n",
       "           'imported_objects': ['FS_MAX_RETRIES',\n",
       "            'SLEEP_MS',\n",
       "            'TIMEOUT_IN_MS']}],\n",
       "         'imported_objects': ['ContractInput', 'Utils']},\n",
       "        {'name': 'widget_framework/src/widget_competing/fake_feature_store.py',\n",
       "         'imports': [],\n",
       "         'imported_objects': ['FakeFeatureStore']},\n",
       "        {'name': 'widget_framework/src/widget_competing/thompson_sampling.py',\n",
       "         'imports': [],\n",
       "         'imported_objects': ['ThompsonSampling']}],\n",
       "       'imported_objects': ['BasePolicy']},\n",
       "      {'name': 'widget_framework/src/widget_competing/policy_factory.py',\n",
       "       'imports': [{'name': 'widget_framework/src/utils.py',\n",
       "         'imports': [{'name': 'widget_framework/constants.py',\n",
       "           'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "             'imports': [],\n",
       "             'imported_objects': ['user_ids_staff']}],\n",
       "           'imported_objects': ['FS_MAX_RETRIES',\n",
       "            'SLEEP_MS',\n",
       "            'TIMEOUT_IN_MS']}],\n",
       "         'imported_objects': ['ContractInput']},\n",
       "        {'name': 'widget_framework/src/widget_competing/epsilong_greedy.py',\n",
       "         'imports': [{'name': 'widget_framework/src/widget_competing/policies.py',\n",
       "           'imports': [{'name': 'widget_framework/src/utils.py',\n",
       "             'imports': [{'name': 'widget_framework/constants.py',\n",
       "               'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "                 'imports': [],\n",
       "                 'imported_objects': ['user_ids_staff']}],\n",
       "               'imported_objects': ['FS_MAX_RETRIES',\n",
       "                'SLEEP_MS',\n",
       "                'TIMEOUT_IN_MS']}],\n",
       "             'imported_objects': ['ContractInput', 'Utils']},\n",
       "            {'name': 'widget_framework/src/widget_competing/fake_feature_store.py',\n",
       "             'imports': [],\n",
       "             'imported_objects': ['FakeFeatureStore']},\n",
       "            {'name': 'widget_framework/src/widget_competing/thompson_sampling.py',\n",
       "             'imports': [],\n",
       "             'imported_objects': ['ThompsonSampling']}],\n",
       "           'imported_objects': ['BasePolicy']}],\n",
       "         'imported_objects': ['EpsilonGreedyPolicy']},\n",
       "        {'name': 'widget_framework/src/widget_competing/policies.py',\n",
       "         'imports': [{'name': 'widget_framework/src/utils.py',\n",
       "           'imports': [{'name': 'widget_framework/constants.py',\n",
       "             'imports': [{'name': 'widget_framework/data/users_staff.py',\n",
       "               'imports': [],\n",
       "               'imported_objects': ['user_ids_staff']}],\n",
       "             'imported_objects': ['FS_MAX_RETRIES',\n",
       "              'SLEEP_MS',\n",
       "              'TIMEOUT_IN_MS']}],\n",
       "           'imported_objects': ['ContractInput', 'Utils']},\n",
       "          {'name': 'widget_framework/src/widget_competing/fake_feature_store.py',\n",
       "           'imports': [],\n",
       "           'imported_objects': ['FakeFeatureStore']},\n",
       "          {'name': 'widget_framework/src/widget_competing/thompson_sampling.py',\n",
       "           'imports': [],\n",
       "           'imported_objects': ['ThompsonSampling']}],\n",
       "         'imported_objects': ['BasePolicy',\n",
       "          'DynamicSegmentsPolicy',\n",
       "          'EpsilonGreedyDoWPolicy',\n",
       "          'PureThompsonSamplingPolicy',\n",
       "          'RandomPolicy']}],\n",
       "       'imported_objects': ['PolicyFactory']}],\n",
       "     'imported_objects': ['WidgetCompeting']},\n",
       "    {'name': 'widget_framework/src/examples/example_test_v2.py',\n",
       "     'imports': [],\n",
       "     'imported_objects': ['get_example_test']}],\n",
       "   'imported_objects': ['WidgetRanker']},\n",
       "  {'name': 'widget_framework/src/examples/example_v2.py',\n",
       "   'imports': [],\n",
       "   'imported_objects': ['get_example_v2']}],\n",
       " 'imported_objects': []}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- widget_framework/src/widget_builder.py\n",
      "  - widget_framework/constants.py\n",
      "      * USERS_STAFF\n",
      "    - widget_framework/data/users_staff.py\n",
      "        * user_ids_staff\n",
      "  - widget_framework/src/experiment_string.py\n",
      "      * ExperimentString\n",
      "    - widget_framework/src/utils.py\n",
      "        * Utils\n",
      "      - widget_framework/constants.py\n",
      "          * FS_MAX_RETRIES\n",
      "          * SLEEP_MS\n",
      "          * TIMEOUT_IN_MS\n",
      "        - widget_framework/data/users_staff.py\n",
      "            * user_ids_staff\n",
      "  - widget_framework/src/user_segmentation/user_segment.py\n",
      "      * UserSegmentation\n",
      "    - widget_framework/src/utils.py\n",
      "        * Utils\n",
      "      - widget_framework/constants.py\n",
      "          * FS_MAX_RETRIES\n",
      "          * SLEEP_MS\n",
      "          * TIMEOUT_IN_MS\n",
      "        - widget_framework/data/users_staff.py\n",
      "            * user_ids_staff\n",
      "  - widget_framework/src/utils.py\n",
      "      * ContractInput\n",
      "      * Utils\n",
      "    - widget_framework/constants.py\n",
      "        * FS_MAX_RETRIES\n",
      "        * SLEEP_MS\n",
      "        * TIMEOUT_IN_MS\n",
      "      - widget_framework/data/users_staff.py\n",
      "          * user_ids_staff\n",
      "  - widget_framework/src/widget_content/widget_content.py\n",
      "      * WidgetContent\n",
      "    - widget_framework/constants.py\n",
      "        * BYO_WIDGET_ID\n",
      "        * MAP_FILTER_NAMES\n",
      "      - widget_framework/data/users_staff.py\n",
      "          * user_ids_staff\n",
      "    - widget_framework/src/utils.py\n",
      "        * ContractInput\n",
      "        * Utils\n",
      "      - widget_framework/constants.py\n",
      "          * FS_MAX_RETRIES\n",
      "          * SLEEP_MS\n",
      "          * TIMEOUT_IN_MS\n",
      "        - widget_framework/data/users_staff.py\n",
      "            * user_ids_staff\n",
      "  - widget_framework/src/widget_ranking/widget_ranker.py\n",
      "      * WidgetRanker\n",
      "    - widget_framework/constants.py\n",
      "        * BUFFER_NUM_WIDGETS\n",
      "      - widget_framework/data/users_staff.py\n",
      "          * user_ids_staff\n",
      "    - widget_framework/src/experiment_string.py\n",
      "        * ExperimentString\n",
      "      - widget_framework/src/utils.py\n",
      "          * Utils\n",
      "        - widget_framework/constants.py\n",
      "            * FS_MAX_RETRIES\n",
      "            * SLEEP_MS\n",
      "            * TIMEOUT_IN_MS\n",
      "          - widget_framework/data/users_staff.py\n",
      "              * user_ids_staff\n",
      "    - widget_framework/src/utils.py\n",
      "        * UNDEF_STR\n",
      "        * ClassGroups\n",
      "        * ContractInput\n",
      "        * FactoryGroups\n",
      "        * ParsedContractInput\n",
      "        * Utils\n",
      "      - widget_framework/constants.py\n",
      "          * FS_MAX_RETRIES\n",
      "          * SLEEP_MS\n",
      "          * TIMEOUT_IN_MS\n",
      "        - widget_framework/data/users_staff.py\n",
      "            * user_ids_staff\n",
      "    - widget_framework/src/widget_competing/widget_competing.py\n",
      "        * WidgetCompeting\n",
      "      - widget_framework/src/utils.py\n",
      "          * ClassGroups\n",
      "          * ContractInput\n",
      "          * Utils\n",
      "        - widget_framework/constants.py\n",
      "            * FS_MAX_RETRIES\n",
      "            * SLEEP_MS\n",
      "            * TIMEOUT_IN_MS\n",
      "          - widget_framework/data/users_staff.py\n",
      "              * user_ids_staff\n",
      "      - widget_framework/src/widget_competing/policies.py\n",
      "          * BasePolicy\n",
      "        - widget_framework/src/utils.py\n",
      "            * ContractInput\n",
      "            * Utils\n",
      "          - widget_framework/constants.py\n",
      "              * FS_MAX_RETRIES\n",
      "              * SLEEP_MS\n",
      "              * TIMEOUT_IN_MS\n",
      "            - widget_framework/data/users_staff.py\n",
      "                * user_ids_staff\n",
      "        - widget_framework/src/widget_competing/fake_feature_store.py\n",
      "            * FakeFeatureStore\n",
      "        - widget_framework/src/widget_competing/thompson_sampling.py\n",
      "            * ThompsonSampling\n",
      "      - widget_framework/src/widget_competing/policy_factory.py\n",
      "          * PolicyFactory\n",
      "        - widget_framework/src/utils.py\n",
      "            * ContractInput\n",
      "          - widget_framework/constants.py\n",
      "              * FS_MAX_RETRIES\n",
      "              * SLEEP_MS\n",
      "              * TIMEOUT_IN_MS\n",
      "            - widget_framework/data/users_staff.py\n",
      "                * user_ids_staff\n",
      "        - widget_framework/src/widget_competing/epsilong_greedy.py\n",
      "            * EpsilonGreedyPolicy\n",
      "          - widget_framework/src/widget_competing/policies.py\n",
      "              * BasePolicy\n",
      "            - widget_framework/src/utils.py\n",
      "                * ContractInput\n",
      "                * Utils\n",
      "              - widget_framework/constants.py\n",
      "                  * FS_MAX_RETRIES\n",
      "                  * SLEEP_MS\n",
      "                  * TIMEOUT_IN_MS\n",
      "                - widget_framework/data/users_staff.py\n",
      "                    * user_ids_staff\n",
      "            - widget_framework/src/widget_competing/fake_feature_store.py\n",
      "                * FakeFeatureStore\n",
      "            - widget_framework/src/widget_competing/thompson_sampling.py\n",
      "                * ThompsonSampling\n",
      "        - widget_framework/src/widget_competing/policies.py\n",
      "            * BasePolicy\n",
      "            * DynamicSegmentsPolicy\n",
      "            * EpsilonGreedyDoWPolicy\n",
      "            * PureThompsonSamplingPolicy\n",
      "            * RandomPolicy\n",
      "          - widget_framework/src/utils.py\n",
      "              * ContractInput\n",
      "              * Utils\n",
      "            - widget_framework/constants.py\n",
      "                * FS_MAX_RETRIES\n",
      "                * SLEEP_MS\n",
      "                * TIMEOUT_IN_MS\n",
      "              - widget_framework/data/users_staff.py\n",
      "                  * user_ids_staff\n",
      "          - widget_framework/src/widget_competing/fake_feature_store.py\n",
      "              * FakeFeatureStore\n",
      "          - widget_framework/src/widget_competing/thompson_sampling.py\n",
      "              * ThompsonSampling\n",
      "    - widget_framework/src/examples/example_test_v2.py\n",
      "        * get_example_test\n",
      "  - widget_framework/src/examples/example_v2.py\n",
      "      * get_example_v2\n"
     ]
    }
   ],
   "source": [
    "# Print the DAG\n",
    "import_dag_builder.visualize_import_dag(dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DAG exported to 'import_dag.yaml'\n"
     ]
    }
   ],
   "source": [
    "# Optionally, export to YAML for further use (e.g., visualization in React/D3.js)\n",
    "import yaml\n",
    "with open(\"import_dag.yaml\", \"w\") as f:\n",
    "    yaml.dump(dag, f)\n",
    "    print(\"\\nDAG exported to 'import_dag.yaml'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Tuple, Optional, Union\n",
    "\n",
    "class PythonExecutionDependencyGraph:\n",
    "    \"\"\"\n",
    "    Builds a fine-grained dependency graph of Python function/class/method usage.\n",
    "    \n",
    "    It traces from a specific 'entry point' (a function, class constructor, or class method)\n",
    "    in a given file, analyzing only the code paths and symbols that are actually called.\n",
    "    \n",
    "    Major steps:\n",
    "    1. Collect all top-level definitions (functions, classes, methods) in each file.\n",
    "    2. Collect all imports in each file and map each imported symbol to its source file \n",
    "       (if it exists in the project).\n",
    "    3. From the entry point, parse the function/method body. For each call, figure out which\n",
    "       symbol is being invoked, whether local or imported, and continue recursively.\n",
    "    4. Build a nested DAG that lists each node as (file_path, symbol_name) and its children \n",
    "       are the next calls in the chain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_path: str):\n",
    "        \"\"\"\n",
    "        :param root_path: The root directory of the project (absolute or relative).\n",
    "        \"\"\"\n",
    "        self.root_path = Path(root_path).resolve()\n",
    "        \n",
    "        # Cache for definitions: { file_path: { \"functions\": {}, \"classes\": {} } }\n",
    "        # Each function/class dictionary will map <symbol_name> -> <AST node or sub-info>\n",
    "        self.definitions_cache: Dict[Path, Dict[str, Dict[str, Any]]] = {}\n",
    "        \n",
    "        # Cache for imports: { file_path: { \"symbols\": {imported_symbol: source_path}, \"modules\": {alias: module_path}, ... } }\n",
    "        # This helps quickly map from an imported symbol to the actual local definition in another file.\n",
    "        self.imports_cache: Dict[Path, Dict[str, Any]] = {}\n",
    "        \n",
    "        # A memo to avoid re-parsing the same file repeatedly\n",
    "        self.parsed_files: Dict[Path, ast.Module] = {}\n",
    "\n",
    "    def build_execution_dag(self,\n",
    "                            entry_file: str,\n",
    "                            entry_symbol: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Build the dependency graph starting from a specific symbol (function/method/constructor)\n",
    "        in a specific file.\n",
    "        \n",
    "        :param entry_file: The relative path of the file where the entry symbol is defined, \n",
    "                           relative to root_path.\n",
    "        :param entry_symbol: The symbol to trace (e.g., 'my_function', 'MyClass', 'MyClass.my_method').\n",
    "        :return: Nested dictionary representing the execution DAG.\n",
    "        \"\"\"\n",
    "        entry_path = (self.root_path / entry_file).resolve()\n",
    "        \n",
    "        # Parse and index the project so we can resolve references quickly\n",
    "        self._index_file(entry_path)\n",
    "        \n",
    "        # Validate that the entry symbol is known in that file\n",
    "        # entry_symbol can be something like 'MyClass', or 'MyClass.my_method', or just 'my_function'\n",
    "        # We'll parse out the top-level piece and possibly a sub-method\n",
    "        top_level_name, sub_method_name = self._split_symbol(entry_symbol)\n",
    "        \n",
    "        if top_level_name not in self.definitions_cache[entry_path][\"functions\"] \\\n",
    "           and top_level_name not in self.definitions_cache[entry_path][\"classes\"]:\n",
    "            raise ValueError(f\"Entry symbol '{top_level_name}' not found in {entry_file}\")\n",
    "        \n",
    "        # Build a DAG node for the entry point\n",
    "        # We'll store nodes in the form { \"file\": <path>, \"symbol\": <symbol>, \"calls\": [sub-nodes], ... }\n",
    "        visited = set()  # track visited (file, symbol) to avoid cycles\n",
    "        dag = self._trace_symbol_usage(entry_path, entry_symbol, visited)\n",
    "        return dag\n",
    "\n",
    "    def _trace_symbol_usage(self,\n",
    "                            file_path: Path,\n",
    "                            symbol: str,\n",
    "                            visited: set) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Recursively build the usage subtree for a single symbol in a file.\n",
    "        \n",
    "        :param file_path: Absolute path to the file.\n",
    "        :param symbol: The symbol to trace (like 'MyClass.my_method' or 'my_function').\n",
    "        :param visited: A set of visited (file_path, symbol) pairs to prevent infinite loops.\n",
    "        :return: A dictionary describing the node, e.g.:\n",
    "                 {\n",
    "                   \"file\": \"src/moduleA.py\",\n",
    "                   \"symbol\": \"MyClass.my_method\",\n",
    "                   \"calls\": [ <child_nodes> ]\n",
    "                 }\n",
    "        \"\"\"\n",
    "        node = {\n",
    "            \"file\": str(file_path.relative_to(self.root_path)),\n",
    "            \"symbol\": symbol,\n",
    "            \"calls\": []\n",
    "        }\n",
    "        \n",
    "        # Detect recursion\n",
    "        sig = (file_path, symbol)\n",
    "        if sig in visited:\n",
    "            return node\n",
    "        visited.add(sig)\n",
    "        \n",
    "        top_level_name, sub_method_name = self._split_symbol(symbol)\n",
    "\n",
    "        # Figure out whether this is a function or a class\n",
    "        definitions = self.definitions_cache[file_path]\n",
    "        if top_level_name in definitions[\"functions\"]:\n",
    "            # We have a top-level function\n",
    "            func_node = definitions[\"functions\"][top_level_name]\n",
    "            calls = self._get_function_calls(file_path, func_node)\n",
    "            child_nodes = self._resolve_calls(file_path, calls, visited)\n",
    "            node[\"calls\"] = child_nodes\n",
    "        \n",
    "        elif top_level_name in definitions[\"classes\"]:\n",
    "            # We have a class\n",
    "            class_info = definitions[\"classes\"][top_level_name]\n",
    "            \n",
    "            if sub_method_name:\n",
    "                # We are specifically tracing e.g. MyClass.my_method\n",
    "                if sub_method_name not in class_info[\"methods\"]:\n",
    "                    raise ValueError(f\"Method '{sub_method_name}' not found in class '{top_level_name}'\")\n",
    "                method_node = class_info[\"methods\"][sub_method_name]\n",
    "                calls = self._get_function_calls(file_path, method_node)\n",
    "                child_nodes = self._resolve_calls(file_path, calls, visited)\n",
    "                node[\"calls\"] = child_nodes\n",
    "            else:\n",
    "                # No sub-method specified; treat as a constructor call or general class usage\n",
    "                # In some code, \"MyClass()\" might trigger __init__, or you might just reference class attributes.\n",
    "                # For simplicity, let's assume it references __init__ if present.\n",
    "                if \"__init__\" in class_info[\"methods\"]:\n",
    "                    method_node = class_info[\"methods\"][\"__init__\"]\n",
    "                    calls = self._get_function_calls(file_path, method_node)\n",
    "                    child_nodes = self._resolve_calls(file_path, calls, visited)\n",
    "                    node[\"calls\"] = child_nodes\n",
    "        \n",
    "        else:\n",
    "            # Unknown symbol => possibly local variable or undefined import\n",
    "            # We do nothing because it's not a recognized function/class\n",
    "            pass\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def _split_symbol(self, symbol: str) -> Tuple[str, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Splits something like 'MyClass.my_method' into ('MyClass', 'my_method') \n",
    "        or just 'my_function' into ('my_function', None).\n",
    "        \"\"\"\n",
    "        parts = symbol.split(\".\")\n",
    "        if len(parts) == 1:\n",
    "            return parts[0], None\n",
    "        else:\n",
    "            return parts[0], parts[1]\n",
    "\n",
    "    def _resolve_calls(self,\n",
    "                       file_path: Path,\n",
    "                       calls: List[Tuple[str, str]],\n",
    "                       visited: set) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Given a list of calls from a function body, return the child DAG nodes\n",
    "        corresponding to each call (only for local or in-project dependencies).\n",
    "        \n",
    "        Each element in 'calls' is (qualifier, func_name). 'qualifier' might be a local variable\n",
    "        or an imported symbol; 'func_name' is the attribute or method being invoked. \n",
    "        If there's no explicit qualifier (i.e. calling a local function by name), it might be (None, 'local_func').\n",
    "        \n",
    "        :param file_path: The file in which these calls occur.\n",
    "        :param calls: A list of calls discovered by `_get_function_calls`.\n",
    "        :param visited: A set of visited (file, symbol) to avoid cycles.\n",
    "        :return: A list of child nodes for the DAG.\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        \n",
    "        for (qualifier, func_name) in calls:\n",
    "            if qualifier is None:\n",
    "                # Means a local function or top-level reference\n",
    "                # Check if it matches a local function name or a class name\n",
    "                definitions = self.definitions_cache[file_path]\n",
    "                if func_name in definitions[\"functions\"]:\n",
    "                    child_symbol = func_name\n",
    "                    child_node = self._trace_symbol_usage(file_path, child_symbol, visited)\n",
    "                    children.append(child_node)\n",
    "                elif func_name in definitions[\"classes\"]:\n",
    "                    # Possibly calling a class like a constructor\n",
    "                    child_symbol = func_name\n",
    "                    child_node = self._trace_symbol_usage(file_path, child_symbol, visited)\n",
    "                    children.append(child_node)\n",
    "                else:\n",
    "                    # Not found among local definitions => might be built-in or external\n",
    "                    pass\n",
    "            else:\n",
    "                # We have something like imported_symbol.some_method or local_var.some_method\n",
    "                # We need to see if 'qualifier' is a known import or a local definition\n",
    "                # If it's an import, see if that import is in project scope, then continue\n",
    "                # If it's local, we could do alias tracking, but that complicates things a lot\n",
    "                # For now, assume that if 'qualifier' matches an imported symbol, we jump there\n",
    "                import_info = self.imports_cache[file_path]\n",
    "                \n",
    "                # 'qualifier' might directly match an import from \"symbols\" or something\n",
    "                if qualifier in import_info[\"symbols\"]:\n",
    "                    # Then the source is local to a different file\n",
    "                    imported_file = import_info[\"symbols\"][qualifier]  # Path to the source\n",
    "                    # We must ensure that the source file is indexed\n",
    "                    self._index_file(imported_file)\n",
    "                    \n",
    "                    # Now see if the imported file has a class/function named func_name\n",
    "                    # or if the qualifier was itself a module import\n",
    "                    definitions = self.definitions_cache[imported_file]\n",
    "                    \n",
    "                    # If we do 'from X import MyClass', qualifier=MyClass, then func_name=some_method\n",
    "                    if func_name in definitions[\"classes\"]:\n",
    "                        child_symbol = f\"{func_name}\"\n",
    "                        # sub-method usage => MyClass.my_method\n",
    "                        # We'll store it as \"MyClass.my_method\"\n",
    "                        # But we only do that if we can confirm a method usage\n",
    "                        # For now, let's treat it as a method reference. This is approximate:\n",
    "                        child_symbol = f\"{func_name}.{func_name.lower()}\"  # naive guess or we might parse the call further\n",
    "                        # Instead, let's just do \"MyClass\" so we have a node, and then inside that node \n",
    "                        # we would see calls to sub-method. The more precise approach is to store \n",
    "                        # the sub-method name (like \"MyClass.my_method\") if we know it from the call. \n",
    "                        #\n",
    "                        # For clarity, let's assume the function name is the sub-method:\n",
    "                        # child_symbol = f\"{func_name}.{func_name_called}\"\n",
    "                        \n",
    "                        # But if this call is indeed MyClass() => user is calling constructor => child_symbol = 'MyClass'\n",
    "                        # or MyClass.my_method => child_symbol = 'MyClass.my_method'\n",
    "                        child_symbol = f\"{func_name}.{func_name}\"  # you would refine logic here\n",
    "                        \n",
    "                        child_node = self._trace_symbol_usage(imported_file, child_symbol, visited)\n",
    "                        children.append(child_node)\n",
    "                    \n",
    "                    elif func_name in definitions[\"functions\"]:\n",
    "                        # If the symbol is a top-level function\n",
    "                        child_symbol = func_name\n",
    "                        child_node = self._trace_symbol_usage(imported_file, child_symbol, visited)\n",
    "                        children.append(child_node)\n",
    "                    else:\n",
    "                        # Could be a variable import or something external\n",
    "                        pass\n",
    "                else:\n",
    "                    # Possibly a local variable that references some object. \n",
    "                    # Full, correct handling would require dataflow analysis \n",
    "                    # to see what 'qualifier' is assigned to. That is more complex.\n",
    "                    pass\n",
    "        \n",
    "        return children\n",
    "\n",
    "    def _get_function_calls(self,\n",
    "                            file_path: Path,\n",
    "                            function_node: ast.AST) -> List[Tuple[Optional[str], str]]:\n",
    "        \"\"\"\n",
    "        Inspect the AST of a function or method body, returning a list of calls in the form \n",
    "        (qualifier, func_name). For example, \"foo.bar()\" => (qualifier='foo', func_name='bar').\n",
    "        A direct call \"some_function()\" => (None, 'some_function').\n",
    "        \n",
    "        This does not do complicated dataflow to track renames or assignments, but can handle\n",
    "        simple patterns.\n",
    "        \"\"\"\n",
    "        calls = []\n",
    "        for node in ast.walk(function_node):\n",
    "            if isinstance(node, ast.Call):\n",
    "                # If it's a simple call like <Name>(...), e.g. my_func(...)\n",
    "                if isinstance(node.func, ast.Name):\n",
    "                    calls.append((None, node.func.id))\n",
    "                # If it's an attribute reference like <Name>.<attr>(...), e.g. foo.bar(...)\n",
    "                elif isinstance(node.func, ast.Attribute):\n",
    "                    # node.func.value might be an ast.Name \n",
    "                    if isinstance(node.func.value, ast.Name):\n",
    "                        qualifier = node.func.value.id  # e.g. 'foo'\n",
    "                        method = node.func.attr  # e.g. 'bar'\n",
    "                        calls.append((qualifier, method))\n",
    "                    # If it's something more nested, we skip or handle further\n",
    "        return calls\n",
    "\n",
    "    def _index_file(self, file_path: Path) -> None:\n",
    "        \"\"\"\n",
    "        Parse a file to:\n",
    "          1) Cache its AST\n",
    "          2) Identify all top-level functions, classes, and their methods\n",
    "          3) Identify local imports and store them in self.imports_cache\n",
    "        \"\"\"\n",
    "        if file_path in self.parsed_files:\n",
    "            return  # Already done\n",
    "\n",
    "        if not file_path.exists() or not file_path.is_file():\n",
    "            # Possibly an external import\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            file_content = file_path.read_text(encoding=\"utf-8\")\n",
    "            tree = ast.parse(file_content, filename=str(file_path))\n",
    "            self.parsed_files[file_path] = tree\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse {file_path}: {e}\")\n",
    "            return\n",
    "\n",
    "        # Initialize caches for this file\n",
    "        self.definitions_cache[file_path] = {\n",
    "            \"functions\": {},   # name -> AST node\n",
    "            \"classes\": {}      # name -> { \"node\": ClassDef, \"methods\": {method_name: AST node} }\n",
    "        }\n",
    "        self.imports_cache[file_path] = {\n",
    "            \"symbols\": {},     # e.g., { \"Utils\": Path(...), \"MyClass\": Path(...) }\n",
    "            \"modules\": {}      # e.g., { \"sys\": None, \"requests\": None } => external or not found\n",
    "        }\n",
    "\n",
    "        # Populate definitions\n",
    "        for node in tree.body:\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                # top-level function\n",
    "                func_name = node.name\n",
    "                self.definitions_cache[file_path][\"functions\"][func_name] = node\n",
    "            elif isinstance(node, ast.ClassDef):\n",
    "                # top-level class\n",
    "                class_name = node.name\n",
    "                methods = {}\n",
    "                # gather methods\n",
    "                for body_item in node.body:\n",
    "                    if isinstance(body_item, ast.FunctionDef):\n",
    "                        methods[body_item.name] = body_item\n",
    "                self.definitions_cache[file_path][\"classes\"][class_name] = {\n",
    "                    \"node\": node,\n",
    "                    \"methods\": methods\n",
    "                }\n",
    "\n",
    "        # Populate imports (only keep references to local files in the project)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Import):\n",
    "                for alias in node.names:\n",
    "                    imported_name = alias.name  # e.g. 'os', 'my_package.module'\n",
    "                    as_name = alias.asname if alias.asname else imported_name\n",
    "                    # Try to resolve\n",
    "                    imported_path = self._resolve_import_to_path(imported_name)\n",
    "                    if imported_path:\n",
    "                        # It's in-project\n",
    "                        self.imports_cache[file_path][\"symbols\"][as_name] = imported_path\n",
    "                    else:\n",
    "                        # external or not found\n",
    "                        self.imports_cache[file_path][\"modules\"][as_name] = None\n",
    "            elif isinstance(node, ast.ImportFrom):\n",
    "                if node.module:\n",
    "                    module_name = node.module  # e.g. 'my_package.module'\n",
    "                    imported_path = self._resolve_import_to_path(module_name)\n",
    "                    if imported_path:\n",
    "                        # It's in-project\n",
    "                        for alias in node.names:\n",
    "                            as_name = alias.asname if alias.asname else alias.name\n",
    "                            self.imports_cache[file_path][\"symbols\"][as_name] = imported_path\n",
    "                    else:\n",
    "                        # external or not found\n",
    "                        for alias in node.names:\n",
    "                            as_name = alias.asname if alias.asname else alias.name\n",
    "                            self.imports_cache[file_path][\"modules\"][as_name] = None\n",
    "\n",
    "    def _resolve_import_to_path(self, import_path: str) -> Optional[Path]:\n",
    "        \"\"\"\n",
    "        Attempt to convert an import path (e.g. \"my_package.module\") into an actual .py file \n",
    "        within the project. Return None if it's external or not found.\n",
    "        \"\"\"\n",
    "        # Convert the import path to a file path\n",
    "        # 1) Check if there's an __init__.py\n",
    "        candidate = self.root_path / import_path.replace(\".\", \"/\") / \"__init__.py\"\n",
    "        if candidate.exists():\n",
    "            return candidate.resolve()\n",
    "\n",
    "        # 2) Otherwise check module_name.py\n",
    "        candidate = self.root_path / f\"{import_path.replace('.', '/')}.py\"\n",
    "        if candidate.exists():\n",
    "            return candidate.resolve()\n",
    "\n",
    "        # Not found inside project\n",
    "        return None\n",
    "\n",
    "    def visualize_execution_dag(self, dag: Dict[str, Any], indent: int = 0):\n",
    "        \"\"\"\n",
    "        Pretty print the execution DAG, showing (file, symbol) and nested calls.\n",
    "        \"\"\"\n",
    "        prefix = \"  \" * indent\n",
    "        print(f\"{prefix}- {dag['file']} :: {dag['symbol']}\")\n",
    "        for child in dag.get(\"calls\", []):\n",
    "            self.visualize_execution_dag(child, indent + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: root folder \"machine-learning-platform\", entry file \"product_recommender/api.py\"\n",
    "root = \"/home/david/Documents/glovo/machine-learning-platform\"\n",
    "entry = \"widget_framework/src/widget_builder.py\"\n",
    "entry_symbol = \"WidgetBuilder.run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_graph = PythonExecutionDependencyGraph(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = dep_graph.build_execution_dag(\n",
    "    entry_file=entry,\n",
    "    entry_symbol=entry_symbol\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- widget_framework/src/widget_builder.py :: WidgetBuilder.run\n"
     ]
    }
   ],
   "source": [
    "# 3) Visualize or otherwise use the resulting DAG\n",
    "dep_graph.visualize_execution_dag(dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_localrag",
   "language": "python",
   "name": "kr_localrag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
